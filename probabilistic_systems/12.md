## 確率システム制御特論 第12回 レポート

研究室
学籍番号:
***
>##### 1. 課題：

パーティクルフィルタ（モンテカルロフィルタ）のソースコードを書いて、現在までに構成した他のフィルタと比較するシミュレーションを行ってみよ。なお、ツールは MATLAB でなくても良い。
***
>##### 2. 状態方程式：

非線形、ノイズはカウス分布のシステムを前提にします：
* $x(k+1) = f(x(k)) + bv(k)$, $v\sim N(\mu, \sigma_v)$
* $y(k) = h(x(k)) + w(k)$, $w \sim N(\mu, \sigma_w)$

***
>##### 3. シミュレーション：

標準偏差: $\sigma_v = 1, ~ \sigma_w=10$
シミュレーション ステップ: 50
粒子数: 500

>##### 3-1. シミュレーション 1：

* **$x(k+1) = x(k) + 3 \times cos(\dfrac{x(k)}{10}) + v(k)$**
* **$y(k) = x^3(k) + w(k)$**

Particle Filter の標準偏差$ ^{(1)}$ ＝ 0.063502
Extended Kalman Filter の標準偏差 ＝ 0.127053
`黄色の点はレサンプルした後の粒子:`
![](12_1_1.png)
![](12_1_2.png)

>##### 3-2. シミュレーション 2：

* **$x(k+1) = x(k) + 3 \times cos(\dfrac{x(k)}{10}) + v(k)$**
* **$y(k) = x(k) + w(k)$**

Particle Filter の標準偏差 ＝ 11.368343
Extended Kalman Filter の標準偏差 ＝ 1.797125

![](12_2_1.png)
![](12_2_2.png)

(1): 初期値の偏差が大きので、標準偏差はステップ 10 から計算します
***
>##### 考察：

* 観察方程式は低次元（2次元以下）、もしくは状態方程式が線形の場合、Particle Filter の表現がとても悪い.（Kalman Filter より、遥かにノイズに影響され易い）
* 観察方程式の次元数が大き過ぎると（4次元以上）、推定値は時々ぜんぜん違う場所に飛ばすの場合があります.
* システムパラメーターが適切の場合（$\sigma_v$は$\sigma_w$より遥か小さい、観察方程式が3次元）、Particle Filter の表現が Kalman Filter より良い.
* Particle Filter ノイズは非カウス分布の場合でも使います.

***
>##### 参考文献

1. [satomacoto - Pythonでパーティクルフィルタを実装してみる](http://satomacoto.blogspot.jp/2012/11/python.html)
2. [Particle filter 紹介](http://daweb.ism.ac.jp/koza/koza2008/PF_Nakano20081030.pdf#search='%E3%83%91%E3%83%BC%E3%83%86%E3%82%A3%E3%82%AF%E3%83%AB%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF')  
3. [Qita - 簡単な粒子フィルタの実装](http://qiita.com/shima_x/items/427c914445c9e8910056)
3. [Qita - なぜパーティクルフィルタの推定値に「重み付き平均」が使われるのかを考察してみた](http://qiita.com/MoriKen/items/da8d290dcefad81b478d)
***
>##### ソースコード
* [Github](https://github.com/shinpoi/course/blob/master/probabilistic_systems/12.py) (https://github.com/shinpoi/course/blob/master/probabilistic_systems/12.py)

``` python
# -*- coding: utf-8 -*-
# python 3.5

import numpy as np
import matplotlib.pyplot as plt
import math
# from scipy.stats import norm

#################################
# Parameter
data_length = 50
particle_number = 500
sigma_v = 1
sigma_w = 30


#################################
# State equation
# x(t+1) = f(x(t)) + N(0, sigma_v)
# y(t) = g(x(t)) + N(0, sigma_w)
def f(x):
    return x + 3 * math.cos(x/10.0)


def a(x):
    return 1 - (3 / 10.0) * math.sin(x / 10.0)


def g(x):
    return x**3


def c(x):
    return 3 * x**2

"""
def x_next(x, sig_v):
    return f(x) + np.random.normal(0, sig_v)
"""


def x_next(x, sig_v=10):
    return x + 3 * math.cos(x/10.0) + np.random.normal(0, sig_v)


def y(x, sig_w):
    return g(x) + np.random.normal(0, sig_w)


#################################
# Create Data_Set
TrueData = np.zeros(data_length)
for i in range(1, data_length):
    TrueData[i] = x_next(TrueData[i-1], sigma_v)

ObserveData = np.zeros(data_length)
for i in range(data_length):
    ObserveData[i] = y(TrueData[i], sigma_w)


##################################################################
# ParticleFilter
class ParticleFilter:
    def __init__(self,y_list, x_next, g, sig_w, particle_number):
        self.x_next = x_next
        self.g = g
        self.y_list = y_list
        self.sig_w = sig_w
        self.particle_number = particle_number

        self.X = np.zeros(particle_number)
        self.X_weight = np.ones(particle_number)

    # init particle by Uniform Distribution
    def init_particle(self):
        """
        for i in range(self.particle_number):
            self.X[i] = (np.random.rand()-0.5)*40
        """
        self.X = np.arange(-20, 20, 40/self.particle_number)
        self.X_weight = np.ones(self.particle_number)

    def status_translate(self):
        for i in range(self.particle_number):
            self.X[i] = self.x_next(self.X[i])

    # likelihood = (1/sqrt(2*pi*sig_w)) * exp(-(y-g(x))**2 / sig_w**2)
    def likelihood(self, x, y):
        return np.exp(-(y - self.g(x))**2 / self.sig_w**2)
        # return norm.pdf(y - self.g(x))

    def set_weight(self, y):
        for i in range(self.particle_number):
            self.X_weight[i] *= self.likelihood(self.X[i], y)

    def weight_normalization(self):
        sum_weight = sum(self.X_weight)
        for i in range(self.particle_number):
            self.X_weight[i] = (self.X_weight[i])/sum_weight

    def resample(self):
        X_resapmle = np.zeros(self.particle_number)
        k = 0
        samples = np.random.multinomial(self.particle_number, self.X_weight)
        for i, n in enumerate(samples):
            for j in range(n):
                X_resapmle[k] = self.X[i]
                k += 1
        W_resample = np.ones(self.particle_number)
        return X_resapmle, W_resample

    def filter_step(self, y):
        """
        1. status translate
        2. set weight(by calculate likelihood)
        3. weight normalization
        4. resample -> value of x (by mean)
        """
        self.status_translate()
        self.set_weight(y)
        self.weight_normalization()
        X_resapmle, W_resample = self.resample()
        return X_resapmle, W_resample

    def run_filter(self):
        X_list = np.zeros([len(self.y_list), self.particle_number])
        X_value_list = np.zeros(len(self.y_list))

        self.init_particle()

        for i in range(len(self.y_list)):
            self.X, self.X_weight = self.filter_step(self.y_list[i])
            X_list[i] = self.X
            X_value_list[i] = (np.mean(self.X, axis=0))  # predict x  = mean(X)
            """
            mu, std = norm.fit(self.X)
            X_value_list[i] = mu
            """
        return X_list, X_value_list

# END ParticleFilter
##################################################################


##################################################################
# EKF
# from 8.py (確率システム制御特論 第8回演習のプログラムそのまま使いました)
# x(k+1) = f(x(x)) + bv(k)
# y(k) = h(x(k)) + w(k)
# ( f(x), b, h(x), A = df(x)/dx, cT = dh(x)/dx, sigma_v, sigma_w
class EKF(object):
    def __init__(self,y_list, f, b, h, A, cT, sigv, sigw, x0=0):
        self.y_list = y_list
        self.f = f
        self.b = b
        self.h = h
        self.A = A
        self.cT = cT
        self.sigma_v = sigv
        self.sigma_w = sigw
        self.x0 = x0

        self.x_guess_prior_next = f
        self.x_list = [x0]

    # function
    def x_next(self, x):
        return self.f(x) + self.b * np.random.normal(0, self.sigma_v)

    def y(self, x):
        return self.h(x) + np.random.normal(0, self.sigma_w)

    # Filter update
    def p_prior_next(self, p_prior, a_k):
        return a_k**2 * p_prior + self.sigma_v**2 * self.b**2

    def g(self, p_prior, cT_k):
        return (p_prior * cT_k) / (cT_k**2 * p_prior + self.sigma_w**2)

    def x_guess_next(self, x_guess_prior, g_k, y_k):
        return x_guess_prior + g_k * (y_k - self.h(x_guess_prior))

    @staticmethod
    def p(g_k, p_prior, cT_k):
        return (1 - g_k * cT_k) * p_prior

    # Extended Kalman Filter
    def run(self, x_g_0, p0):
        # create dataset
        x_guess_list = [0]
        y_list = self.y_list

        # Filter
        x_guess_k = x_g_0
        p_k = p0
        for y_k in y_list:
            x_gp_k = self.x_guess_prior_next(x_guess_k)
            a_k = self.A(x_gp_k)
            cT_k = self.cT(x_gp_k)
            p_prior_k = self.p_prior_next(p_k, a_k)
            g_k = self.g(p_prior_k, cT_k)
            x_guess_k = self.x_guess_next(x_gp_k, g_k, y_k)
            p_k = self.p(g_k, p_prior_k, cT_k)
            x_guess_list.append(x_guess_k)
        return x_guess_list[1:]
# END EKF
##################################################################

# Run
p1 = ParticleFilter(y_list=ObserveData, x_next=x_next, g=g, sig_w=sigma_w, particle_number=particle_number)
ekf = EKF(y_list=ObserveData, f=f, b=1, h=g, A=a, cT=c, sigv=sigma_v, sigw=sigma_w, x0=0)

particle_list, predict_data = p1.run_filter()
particle_list_ekf = ekf.run(x_g_0=0, p0=1)

"""
#  data check
print(len(TrueData), len(ObserveData), len(predict_data))
print(type(particle_list), TrueData.shape)
print(type(TrueData), TrueData.shape)
print(type(ObserveData), ObserveData.shape)
print(type(predict_data), predict_data.shape)

for i in range(len(particle_list)):
    for j in range(len(particle_list[i])):
        if particle_list[i][j] > 100.0:
            print("overflow p[%d][%d] : %f" % (i, j, particle_list[i][j]))
"""


# Evaluate
PF_deviation = np.zeros(data_length)
EKF_deviation = np.zeros(data_length)
for i in range(10, data_length):
    PF_deviation[i] = (predict_data[i] - TrueData[i])**2
    EKF_deviation[i] = (particle_list_ekf[i] - TrueData[i])**2

sigma_PF = math.sqrt(sum(PF_deviation)/data_length)
sigma_EKF = math.sqrt(sum(EKF_deviation)/data_length)

print("Standard deviation of ParticleFilter is: %f" % sigma_PF)
print("Standard deviation of ExtendedKalmanFilter is: %f" % sigma_EKF)


# Plot (True - Observe - PF)
plt.figure(1, figsize=(16, 9))
# plt.axis([0, 50, -80, 80])
plt.plot(range(data_length), TrueData, label="True Value", color="blue", linewidth=1)
# plt.plot(range(data_length), ObserveData, label="Observe Value", color="gray", linewidth=1)
plt.plot(range(data_length), predict_data, label="Predict Value", color="red", linewidth=1)
# plt.plot(range(data_length), p_test, '.', color="gray")
plt.plot(range(data_length), particle_list, '.', color="yellow")
plt.xlabel("k")
plt.ylabel("value")
plt.title("Particle Filter")
plt.legend()

# Plot (True - PF - EKF)
plt.figure(2, figsize=(16, 9))
plt.plot(range(data_length), TrueData, label="True value", color="blue", linewidth=1)
# plt.plot(range(data_length), ObserveData, label="Observe Value", color="gray", linewidth=1)
plt.plot(range(data_length), predict_data, label="PF Value", color="red", linewidth=1)
plt.plot(range(data_length), particle_list_ekf, label="EKF Value", color="green", linewidth=1)
plt.xlabel("k")
plt.ylabel("value")
plt.title("Particle Filter - Kalman Filter")
plt.legend()

plt.show()
```
