RDD
------------------------------------------
* a datastruct


* iput(transfer the ordata to rdd)  
* transfer(->DAG)  
* cache  
* action

shared variables
------------------------------------------
* Broadcast Variables
  * val broadcastVar = sc.broadcast(Array(1, 2, 3))


* accumulator
  * val accum = sc.accumulator(0)

sc.textFile("file:///")  
sc.textFile("hdfs:///")

>RDD Operations :　<!!-- Target:RDD -->
http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations

    action  
`.reduce(func)`  //return a value
  * `e.g def func{_+_}; means sum of _ `  

`.count()`  //count number of element  
`.collect()`  //return a array  
`.take(n)`  //take element 1~n  
`.first()`  //aslo take(1)      
`.saveAsTextFile(path)`      
`.filter(func):`  //return a rdd if func returns true  
  * `_.startsWith(str)`    
  * `_.contains(str)`  


    transfer
`.map(func)`  //return a rdd  
`.distinct([numTasks]))` //dele distinct elements  
`.union(rdd_object)`  

    cache & others
`.persist()`  //cache to memory  
`.toDebugString`  //show LineAge  

scala
------------------------------------------
`java.array[n] == scala.array(n)`  
`a => b : 转化符号,把任何a映射为b的函数`
  * `e.g. count : words.map(x=>(x,1)).reduceByKey(_+_)`
